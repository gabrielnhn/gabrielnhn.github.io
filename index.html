<!DOCTYPE html>
<head>
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<!-- <div class="link-container">
    <a class="link" href="./index.html">Home</a> 
    <a class="link" href="./CV.pdf">Curriculum</a>
</div> -->

<body>
<div class="section">

    <div id="upperblock">
        <div class="image_name">
            <img class="profile-picture" src="https://avatars.githubusercontent.com/u/55661167?v=4">
            <div id="text-beside">
                <div id="contact">
                    <h1>Gabriel Nascarella Hishida</h1>
                    <p><i class="fa fa-envelope-square"> </i> gabrielnhn @ duck . com</p>
                    <p><i class="fa fa-linkedin-square"></i> <a class="link-small" href="https://www.linkedin.com/in/gabriel-nascarella-hishida/">LinkedIn</a>/gabriel-nascarella-hishida</p>
                    <p><i class="fa fa-github"></i> <a class="link-small" href="https://github.com/gabrielnhn/">GitHub</a>/gabrielnhn</p>
                
                </div>
            </div>
        </div>
        
    </div>
   

    <div id="aboutme">
        <p >
            I'm a masters student in Data Science and Artificial Intelligence at <a href="https://www.tudelft.nl/">Delft University of Technology üá≥üá±</a>.<br>
            My interests lie in computer vision, robotics and deep learning.<br>
            <br>
            Before this, I graduated with honours in BSc Computer Science at <a href="https://ufpr.br/">UFPR üáßüá∑</a>,
            <br> and was doing research on ML/CNNs/GANs in the Laboratory of Vision, Robotics and Imaging <a href="https://web.inf.ufpr.br/vri/">(VRI)</a>.
        </p>
    </div>
</div>

<div id="lowersections">
    
    <div class="section">
        
        <h2>Projects</h2>
        
        <iframe width="560" height="315" src="https://www.youtube.com/embed/ufpI7cly8JM?si=8P1sLh-2CuRiOdMD" title="YouTube video player" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <p>I was part of a robotics team called <a href="https://www.facebook.com/ufpr.yapira">Yapira UFPR </a> Robotics Team.<br> We received an award for out camera-based line follower robot in RCX 2023.</p>
        
    </div>

    <div class="section">
        <h3>Favourite University Projects</h3>
        <img src="exp3.png" width="auto">
        <h4>‚ÄùUsing Conditional Generative Adversarial Networks for Data Augmentation in Pneumothorax
        Classification‚Äù</h4>
        <p>Experimented on GAN architectures in order to generate lung images from poor segmentation inputs for pneumothorax classification (<a href="https://drive.google.com/file/d/1_kYF7IAo4eA9TCQSblHp1RdM7QYxd0Gh/view?usp=sharing">PDF</a>, <a href="https://gitlab.c3sl.ufpr.br/gnhnascimento/cgan-pneumothorax">GitLab</a>)</p>
        
        <img src="mosaic.png">
        <h4>‚ÄùPhotomosaic from dominant patch color‚Äù</h4>
        <p>Based on 20x20 .ppm tiles. <a href="https://github.com/gabrielnhn/photomosaic">GitHub</a></p>

        
    </div>

    <div class="section">

        <h2>Publications (From BSc.)</h2>

        <iframe width="560" height="315" src="https://www.youtube.com/embed/_muyewFN-GU?si=MZVZuNZVBp-f8C8U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <h4>"Look where you‚Äôre going: Classifying drivers' attention through 3D gaze estimation". 2022 Bsc thesis</h4>
        <p><a href="./Thesis_LWYG.pdf">PDF</a> | <a href="https://github.com/VRI-UFPR/LWYG-drivers-attention">GitHub Repo</a></p>

        <iframe width="560" height="315" src="https://www.youtube.com/embed/s49nZorNE7A?si=ZF9m_jqcMP3TEM2f" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <h4>"VRI-GazeNet: 3D Gaze Estimation for Real-time Applications" LARS 2023</h4>
        <p><a href="http://dx.doi.org/10.1109/LARS/SBR/WRE59448.2023.10333044">PDF</a> | <a href="https://github.com/VRI-UFPR/GazeNet">GitHub Repo</a></p>

    </div>
</div>

</body>